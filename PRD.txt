PRD & Architecture — Discord Observer/Orchestrator (Pilot)

Owner: Jack (Latrobe Consulting Group)
Doc goals: Define a minimal but complete pilot that ingests Discord messages as signals, tags them with a nano‑LLM, classifies user intent in an observer, and takes actions through an orchestrator using discrete Discord I/O classes — all running in a single container.
Tone: Skeptical, practical, opinionated. We will ruthlessly keep this tight.

0) Executive Summary

We will ship a containerized service that:

Normalizes inputs into a generic Signal model and a DiscordMessage subclass.

Ingests Discord messages via a small interface service and converts them into DiscordMessage signals.

Observes using a tiny LLM (“GPT‑5‑nano” placeholder) to decide: is this a help request? a problem report? neither?

Orchestrates responses using an agent with tool access, most importantly a separate Discord Responder Tool that replies in the correct channel/thread/message context.

Logs all decisions/actions for audit, with dead‑simple persistence (SQLite) and a narrow admin API for observability.

Runs in a single container, with async tasks; no tests for now (pilot), but with clean seams to evolve.

1) Goals, Non‑Goals, Success
Goals

G1. End‑to‑end path from Discord message → normalized Signal → observer classification → orchestrator action → Discord reply.

G2. Two discrete Discord classes: one pulls/parses (DiscordIngestClient), the other posts (DiscordResponderTool).

G3. LLM‑lite: Use a small/cheap model for (a) fast tags (purpose/sentiment) and (b) observer intent (“help” vs “problem” vs “other”).

G4. Operator trust: Deterministic logging, idempotency, rate‑limit respect, basic metrics.

G5. Containerized: One image; runs locally or in a small cloud VM.

Non‑Goals (Pilot)

NG1. No cross‑platform ingestion beyond Discord.

NG2. No human moderation console. (We log to DB; use sqlite3/SELECT or simple admin endpoints.)

NG3. No advanced memory/knowledge base, no vector search.

NG4. No fine‑tuning; prompt only.

NG5. No test suite (explicitly avoided per request).

Success Metrics (first 2 weeks)

S1. ≥95% of replies are posted to the correct Discord context (channel/thread/reply target).

S2. Observer precision for (help ∪ problem) ≥80% on a convenience sample of 100 messages.

S3. Mean end‑to‑end latency ≤2.0s P50 (≤5.0s P95) for non‑rate‑limited channels.

S4. Zero bot crashes over 24h during soak.

2) User Stories

As a community member, if I ask for help or report a problem in a server channel, I receive a timely response that references my message.

As an operator, I can verify what the system did for any message: raw content, tags, observer decision, tool calls, and posted response.

3) High‑Level Architecture
flowchart LR
  subgraph Discord
    A[Discord Gateway/Events]
    B[Discord REST API]
  end

  subgraph Container (Single Image)
    I[DiscordIngestService\n(DiscordIngestClient)]
    N[NanoClassifier\n(purpose/sentiment)]
    S[Signal Bus\n(asyncio.Queue)]
    O[Observer\n(GPT-5-nano)]
    Q[Orchestrator\n(Agent + Tools)]
    R[DiscordResponderTool]
    DB[(SQLite)]
    AP[Admin API\n(health/metrics)]
  end

  A --> I -->|"DiscordMessage (Signal)"| S
  S --> N -->|"tags"| O
  O -->|"decision"| Q
  Q -->|"action: reply"| R
  R --> B

  I --> DB
  N --> DB
  O --> DB
  Q --> DB
  R --> DB
  AP --> DB


Why one container? Minimal ops overhead. We keep clear module boundaries; if we later split, seams are already in place.

4) Data Model (Minimal, explicit)
4.1 Signal (base)
{
  "signal_id": "src:discord:msg:1122334455",
  "source": "discord",
  "created_at": "2025-09-15T10:05:12Z",
  "author": { "user_id": "12345", "username": "alice" },
  "context": {
    "guild_id": "G1",
    "channel_id": "C1",
    "thread_id": "T1",
    "message_id": "M1",
    "reply_to_id": "M0"
  },
  "content": "my build keeps failing, can anyone help?",
  "nano_tags": {
    "purpose": "support|chatter|spam|unknown",
    "sentiment": "neg|neu|pos",
    "urgency": "low|med|high",
    "toxicity": false
  },
  "observer": {
    "intent": "help_request|problem_report|other",
    "confidence": 0.86,
    "rationale": "short string"
  },
  "orchestrator": {
    "status": "pending|responded|skipped|escalated",
    "plan": "reply|noop|escalate",
    "action_log_ids": ["A123"]
  },
  "metadata": { "lang": "en" }
}

4.2 DiscordMessage (extends Signal)

Adds: guild_name, channel_name, attachments, embeds, mentions.

4.3 ActionLog
{
  "action_id": "A123",
  "signal_id": "S123",
  "action": "discord.reply",
  "request": { "channel_id": "C1", "message_id": "M1", "mode": "reply", "text": "..." },
  "response": { "http_status": 200, "discord_message_id": "M2" },
  "ts": "2025-09-15T10:05:14Z"
}


Storage: SQLite with 3 tables (signals, actions, kv). We store nano_tags/observer/orchestrator as JSON columns.

5) Component Specs
5.1 Signal class (generic)

Responsibility: Unified envelope for any message‑like event.

Core methods:

Signal.fast_classify(nano_llm) -> nano_tags (purpose/sentiment/urgency/toxicity)

Signal.key() for idempotency (source + message_id).

Opinion: Keep Signal small; don’t bake in platform logic. Add only fields that every platform can satisfy.

Python sketch

# signals/base.py
from pydantic import BaseModel, Field
from typing import Optional, Dict, Any, List
from datetime import datetime

class Signal(BaseModel):
    signal_id: str
    source: str
    created_at: datetime
    author: Dict[str, str]
    context: Dict[str, Optional[str]]  # guild_id, channel_id, thread_id, message_id, reply_to_id
    content: str
    nano_tags: Dict[str, Any] = Field(default_factory=dict)
    observer: Dict[str, Any] = Field(default_factory=dict)
    orchestrator: Dict[str, Any] = Field(default_factory=dict)
    metadata: Dict[str, Any] = Field(default_factory=dict)

    async def fast_classify(self, nano_llm) -> Dict[str, Any]:
        # Prompt truncated for brevity; returns small dict
        return await nano_llm.classify(self.content)

5.2 Discord API interface (ingest) — DiscordIngestClient

Responsibility: Retrieve messages visible to the installed bot and convert to DiscordMessage.

Mechanics:

Uses Discord gateway intents (message content must be enabled in the app settings).

Handles only create events for new messages (no edits/deletes for pilot).

Applies basic filters (ignore bot messages, DMs optional).

Pushes DiscordMessage onto the internal async queue.

Class contract

class DiscordIngestClient:
    async def start(self): ...
    async def stop(self): ...
    async def on_message(self, raw_event) -> "DiscordMessage": ...


DiscordMessage

# signals/discord.py
from .base import Signal

class DiscordMessage(Signal):
    guild_name: str | None = None
    channel_name: str | None = None
    attachments: list = []
    embeds: list = []
    mentions: list = []


Service: DiscordIngestService runs the client, performs dedup (by signal_id), persists to DB, places onto SignalBus.

5.3 Observer process — “dumb but decisive”

Responsibility: For each incoming Signal, decide one of: help_request, problem_report, other. No actions.

LLM: Tiny (GPT‑5‑nano placeholder). Provide a short, stable prompt with strict schema.

Output: Write observer.intent, observer.confidence, observer.rationale to the signal row; publish decision to the orchestrator queue.

Sketch

class Observer:
    def __init__(self, llm, bus, db): ...
    async def handle(self, sig: Signal):
        sig.nano_tags = sig.nano_tags or await sig.fast_classify(self.llm)
        decision = await self.llm.intent(sig.content)
        sig.observer = decision
        db.save_signal(sig)
        if decision["intent"] in ("help_request", "problem_report"):
            await bus.publish(("observer.flagged", sig.signal_id))


Prompt heuristic (concise)

Help request cues: “how do I…”, “can someone help”, “stuck with…”, “where is…”.

Problem report cues: “bug”, “error”, “doesn’t work”, stack traces, screenshots, “regression”.

5.4 Orchestrator (agentic; tool‑use)

Responsibility: Given a flagged Signal, plan and execute an action, primarily a Discord reply.

Policy (pilot):

help_request → reply with guidance template + ask 1 clarifying question.

problem_report → reply with acknowledgment + ask for reproducible details (env, steps, expected vs actual).

other → noop.

Tools: Minimal Tool API (LangChain‑like), with DiscordResponderTool registered.

Awareness of context: The tool receives the original Signal, ensuring reply goes to the correct channel/thread and references the message id.

Sketch

class Orchestrator:
    def __init__(self, tools, db):
        self.tools = {t.name: t for t in tools}
    async def handle_flag(self, signal: Signal):
        plan = self.plan(signal)
        if plan["action"] == "reply":
            text = self.compose_reply(signal)
            await self.tools["discord.respond"].run(signal, text)

    def plan(self, signal):
        intent = signal.observer.get("intent")
        if intent in ("help_request","problem_report"):
            return {"action":"reply"}
        return {"action":"noop"}

5.5 Two discrete Discord classes (hard requirement)

DiscordIngestClient: Only listens/pulls & parses; never posts.

DiscordResponderTool: Only posts; never listens. Receives the Signal for context; posts via REST with correct channel/thread/message reference.

Responder Tool

class DiscordResponderTool:
    name = "discord.respond"
    def __init__(self, http_client, db): ...
    async def run(self, signal: Signal, text: str, mode: str = "reply"):
        req = {
          "channel_id": signal.context["channel_id"],
          "message_id": signal.context["message_id"],
          "thread_id": signal.context.get("thread_id")
        }
        res = await self._post_reply(req, text, mode)
        self._log_action(signal.signal_id, req, res)

5.6 Container/process model

Single Python process with asyncio:

Task 1: DiscordIngestService (gateway event loop)

Task 2: Observer consumer

Task 3: Orchestrator consumer

Task 4: Admin API (FastAPI)

Clean shutdown via signals; graceful drain of queues.

6) End‑to‑End Flows
6.1 New message → reply (happy path)

Discord emits MESSAGE_CREATE.

DiscordIngestClient parses → DiscordMessage.

Store Signal in DB (signals), push to SignalBus.

Observer pops, runs fast_classify and intent, updates DB.

If intent ∈ {help, problem}, publish observer.flagged.

Orchestrator composes a short contextual reply; calls DiscordResponderTool.

Tool replies to the original message (reply chain or thread), records ActionLog.

6.2 Idempotency & retries

Dedup on signal_id (source + message_id).

Outbound replies: if REST call 429/5xx, exponential backoff; record retries; never double‑reply (check ActionLog for prior success).

7) Prompts (minimal, deterministic)
7.1 Nano “fast classifier”

System: “You tag short chat messages. Output compact JSON keys: purpose, sentiment, urgency, toxicity.”
User: <message>
Output (example):

{"purpose":"support","sentiment":"neg","urgency":"med","toxicity":false}

7.2 Observer intent

System: “Classify if the user asks for help, reports a problem, or neither. Return keys: intent (help_request|problem_report|other), confidence (0‑1), rationale (<=20 words).”
User: <message>

8) Orchestrator reply templates (opinionated, short)

help_request
“Thanks for reaching out! Quick pointers: <link or top tip>. Could you share: goal, what you tried, any error text? I’ll tailor next steps.”

problem_report
“Appreciate the report. To reproduce: env (OS/version), steps, expected vs actual, error logs or screenshot. I’ll triage once I have those.”

(Templates can be configured via env or a small YAML. Keep it boring and clear.)

9) Admin & Observability (bare minimum)

Admin API (FastAPI):

GET /healthz → {"ok":true}

GET /metrics → counters (ingested, flagged, replied), latencies (P50/P95).

GET /signals/{id} → full JSON row (for audits).

Metrics:

signals_ingested_total

observer_flagged_total (help/problem)

orchestrator_replies_total

Latencies: ingest→observe, observe→reply.

10) Config & Secrets

DISCORD_BOT_TOKEN (required)

DISCORD_APP_ID (optional; for mentions/commands later)

DISCORD_INTENTS (comma list; must include message content for pilot)

LLM_PROVIDER (e.g., openai), LLM_API_KEY

DB_PATH (default ./data/app.db)

LOG_LEVEL (default INFO)

11) Minimal Directory Layout
app/
  signals/
    base.py
    discord.py
  ingest/
    discord_client.py           # DiscordIngestClient
    service.py                  # DiscordIngestService
  observer/
    observer.py
    nano_llm.py                 # thin wrapper for GPT-5-nano
  orchestrator/
    orchestrator.py
    tools/
      discord_responder.py      # DiscordResponderTool
  infra/
    bus.py                      # asyncio.Queue wrapper
    db.py                       # sqlite ops
    admin_api.py                # FastAPI
  main.py                       # wires tasks
Dockerfile

12) Deployment
Dockerfile (lean)
FROM python:3.11-slim
WORKDIR /app
COPY app/ /app/app
COPY requirements.txt /app/
RUN pip install --no-cache-dir -r requirements.txt
ENV PYTHONUNBUFFERED=1 DB_PATH=/app/data/app.db
RUN mkdir -p /app/data
CMD ["python","-m","app.main"]


Runtime: 256–512MB RAM is enough for the nano calls and gateway client. CPU: 1 vCPU.

13) Risk Register (and stances)

Discord message content intent disabled → Fail to see text.
Mitigation: Hard fail on startup if not granted; clear error.

Over‑replying/noise → Annoy users.
Mitigation: Only reply to (help_request ∪ problem_report); throttle per‑channel; record last reply timestamp per user.

LLM hallucinations → Bad advice.
Mitigation: Use conservative, templated replies; no claims of fixes.

Rate limits → 429 spikes.
Mitigation: Backoff & jitter; track per‑route budgets; queue outbound.

Data retention/PII → Compliance.
Mitigation: 14‑day rolling log in pilot; redact tokens/links via regex; configurable retention.

14) Future‑Proofing (post‑pilot)

Swap SQLite → Postgres; asyncio.Queue → Redis/NATS.

Add policy pack (quiet hours, channels to ignore).

Add slash‑commands and reactions (“🆘” triggers observer).

Add small memory (recent thread context) for higher‑quality replies.

Instrument per‑template outcome tracking (👍/👎 reactions).

15) Skeleton Code (abridged, end‑to‑end)
# app/main.py
import asyncio
from app.infra.bus import SignalBus
from app.infra.db import DB
from app.ingest.service import DiscordIngestService
from app.observer.observer import Observer
from app.orchestrator.orchestrator import Orchestrator
from app.orchestrator.tools.discord_responder import DiscordResponderTool
from app.infra.admin_api import serve_admin

async def main():
    db = DB()
    bus = SignalBus()
    ingest = DiscordIngestService(bus, db)
    observer = Observer(nano_llm=..., bus=bus, db=db)
    responder = DiscordResponderTool(http_client=..., db=db)
    orchestrator = Orchestrator(tools=[responder], db=db, bus=bus)

    await asyncio.gather(
        ingest.run(),
        observer.run(),
        orchestrator.run(),
        serve_admin(db)
    )

if __name__ == "__main__":
    asyncio.run(main())


Key guarantees:

The ingest side and responder tool are physically separate classes/modules.

The tool receives the original Signal to reply in the correct context.

16) What “Done” Looks Like (Pilot)

Container starts cleanly; health endpoint returns OK.

Bot joins a test Discord server (message content intent enabled).

You post: “Can anyone help, I’m getting a 403 from the API.”

System:

stores a Signal with purpose=support, sentiment=neg,

classifies intent=problem_report,

replies in the same thread/message with the problem‑report template,

logs action with the new Discord message ID.

Final Opinion

Keep it boring. One container, one DB file, one queue. Two Discord classes — ingress and egress — with a clean seam the agent can call. Nano models only. Deterministic templates. Everything else can wait until the pilot proves there’s signal worth scaling.